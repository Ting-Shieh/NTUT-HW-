{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============use 10=================\n",
      "54/54 [==============================] - 0s 3ms/step\n",
      "test_loss: 9.849947222956905   avg  test_accuracy: 0.38888888778509917\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 9.849946587174028   avg  test_accuracy: 0.38888889440783747\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 9.849947470205802   avg  test_accuracy: 0.38888889330404774\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 9.849946587174028   avg  test_accuracy: 0.38888889440783747\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 9.849946905065465   avg  test_accuracy: 0.38888889330404774\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 9.849946587174028   avg  test_accuracy: 0.38888889440783747\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 9.849947152314362   avg  test_accuracy: 0.38888888668130944\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 9.849947222956905   avg  test_accuracy: 0.388888892200258\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 9.849947222956905   avg  test_accuracy: 0.388888892200258\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 9.849947152314362   avg  test_accuracy: 0.38888888668130944\n",
      " avg acc: 0.38888889153798417\n",
      "=============use 20=================\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "test_loss: 11.640846923545555   avg  test_accuracy: 0.27777778329672637\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 11.640846499690303   avg  test_accuracy: 0.27777778053725205\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 11.64084713547318   avg  test_accuracy: 0.2777777799853572\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 11.640846499690303   avg  test_accuracy: 0.27777778053725205\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 11.64084713547318   avg  test_accuracy: 0.2777777799853572\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 11.640846994188097   avg  test_accuracy: 0.27777777667398806\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 11.64084642904776   avg  test_accuracy: 0.2777777810891469\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 11.64084706483064   avg  test_accuracy: 0.27777778053725205\n",
      "54/54 [==============================] - 0s 55us/step\n",
      "test_loss: 11.64084642904776   avg  test_accuracy: 0.2777777810891469\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 11.640846499690303   avg  test_accuracy: 0.27777778053725205\n",
      " avg acc: 0.27777778042687307\n",
      "=============use 30=================\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.74539675535979   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396896644875   avg  test_accuracy: 0.33333333609280763\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396190219456   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396190219456   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333322295436\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.74539675535979   avg  test_accuracy: 0.33333333885228195\n",
      "54/54 [==============================] - 0s 56us/step\n",
      "test_loss: 10.74539746178521   avg  test_accuracy: 0.33333333609280763\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396508110893   avg  test_accuracy: 0.3333333377484922\n",
      " avg acc: 0.33333333476826\n",
      "=============use 40=================\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "test_loss: 4.526064766777886   avg  test_accuracy: 0.72222223105254\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 4.61274493182147   avg  test_accuracy: 0.648148137110251\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 4.542813601317229   avg  test_accuracy: 0.6851851873927646\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 4.511037226076479   avg  test_accuracy: 0.7037037125340214\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 4.547367210741396   avg  test_accuracy: 0.6851851940155029\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 4.699194448965567   avg  test_accuracy: 0.6851851873927646\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 4.555181370841132   avg  test_accuracy: 0.6666666777045639\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 4.55491500430637   avg  test_accuracy: 0.685185189600344\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 4.565574910905626   avg  test_accuracy: 0.6851851807700263\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 4.581953861095287   avg  test_accuracy: 0.7037036948733859\n",
      " avg acc: 0.6870370392446163\n",
      "=============use 50=================\n",
      "54/54 [==============================] - 0s 4ms/step\n",
      "test_loss: 10.745396508110893   avg  test_accuracy: 0.3333333377484922\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396190219456   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745397143893772   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396508110893   avg  test_accuracy: 0.3333333377484922\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.74539675535979   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333322295436\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.74539675535979   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396190219456   avg  test_accuracy: 0.3333333311257539\n",
      " avg acc: 0.33333333366447027\n",
      "=============use 60=================\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "test_loss: 10.697900489524558   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 136us/step\n",
      "test_loss: 11.64084706483064   avg  test_accuracy: 0.27777778219293664\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 11.64084706483064   avg  test_accuracy: 0.27777778219293664\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 11.64084642904776   avg  test_accuracy: 0.2777777810891469\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 11.64084642904776   avg  test_accuracy: 0.2777777810891469\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396508110893   avg  test_accuracy: 0.3333333377484922\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 10.69790087805854   avg  test_accuracy: 0.33333333554091277\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.697900100990578   avg  test_accuracy: 0.3333333322295436\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 11.64084642904776   avg  test_accuracy: 0.2777777810891469\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 6.275700851723   avg  test_accuracy: 0.6111111177338494\n",
      " avg acc: 0.3333333367550815\n",
      "=============use 70=================\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333322295436\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 10.74539675535979   avg  test_accuracy: 0.33333333885228195\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 10.74539707325123   avg  test_accuracy: 0.3333333333333333\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333322295436\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 10.745396190219456   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396508110893   avg  test_accuracy: 0.3333333377484922\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396508110893   avg  test_accuracy: 0.3333333377484922\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 147us/step\n",
      "test_loss: 10.745396578753436   avg  test_accuracy: 0.3333333311257539\n",
      " avg acc: 0.33333333476826\n",
      "=============use 80=================\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "test_loss: 0.2602362158121886   avg  test_accuracy: 0.9074074184453046\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 0.16139688480783393   avg  test_accuracy: 0.9444444554823416\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 0.29004253502245303   avg  test_accuracy: 0.8888888999267861\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 0.16581627781744357   avg  test_accuracy: 0.9074074118225662\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 0.17153876826719003   avg  test_accuracy: 0.9074074007846691\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 0.17346183569343002   avg  test_accuracy: 0.9074074118225662\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 0.09649232609404458   avg  test_accuracy: 0.9629629563402247\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 0.11588179568449657   avg  test_accuracy: 0.9814814814814815\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 0.39703335143901686   avg  test_accuracy: 0.8888888933040477\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 0.15899359600411522   avg  test_accuracy: 0.9259259193031876\n",
      " avg acc: 0.9222222248713177\n",
      "=============use 90=================\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "test_loss: 10.745397196875679   avg  test_accuracy: 0.3333333399560716\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333322295436\n",
      "54/54 [==============================] - 0s 74us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 10.74539675535979   avg  test_accuracy: 0.33333333885228195\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.74539707325123   avg  test_accuracy: 0.3333333377484922\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396508110893   avg  test_accuracy: 0.3333333377484922\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 148us/step\n",
      "test_loss: 10.745397532427752   avg  test_accuracy: 0.33333333554091277\n",
      "54/54 [==============================] - 0s 130us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333349890179\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333322295436\n",
      " avg acc: 0.3333333362583761\n",
      "=============use 100=================\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "test_loss: 10.745397603070295   avg  test_accuracy: 0.3333333349890179\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333322295436\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396896644875   avg  test_accuracy: 0.3333333377484922\n",
      "54/54 [==============================] - 0s 129us/step\n",
      "test_loss: 10.74539675535979   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396508110893   avg  test_accuracy: 0.3333333377484922\n",
      "54/54 [==============================] - 0s 110us/step\n",
      "test_loss: 10.745396190219456   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 92us/step\n",
      "test_loss: 10.745396190219456   avg  test_accuracy: 0.3333333311257539\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396826002333   avg  test_accuracy: 0.3333333366447025\n",
      "54/54 [==============================] - 0s 111us/step\n",
      "test_loss: 10.745396896644875   avg  test_accuracy: 0.33333333609280763\n",
      " avg acc: 0.333333334547502\n",
      "max avg acc=> 0.9222222248713177\n"
     ]
    }
   ],
   "source": [
    "# A simple program to illustrate how to use scikit-learn \n",
    "# Wine dataset \n",
    "# Use 3-layer fully connected neural networks\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "raw = datasets.load_wine()\n",
    "# A simple program to illustrate how to use scikit-learn \n",
    "# Wine dataset \n",
    "# Use 3-layer fully connected neural networks\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "raw = datasets.load_wine()\n",
    "# Sample features are in df_X. Shape of df_X is 178 x 13\n",
    "df_X = raw.data\n",
    "# Sample labels are in df_y. Shaper of df_y is 178, 3 classes 0,1, 2\n",
    "# samples are 59, 78, 41 in each class\n",
    "df_y = raw.target\n",
    "\n",
    "# convert to one-hot encoding for output classes\n",
    "Y_3 = to_categorical(df_y)\n",
    "\n",
    "maxtag=0\n",
    "for unitsNumber in range(10,110,10):\n",
    "    print(\"=============use {}=================\".format(unitsNumber))\n",
    "    network = models.Sequential()\n",
    "\n",
    "    network.add(Dense(units=unitsNumber, activation='relu', input_dim=13)) # unitsNumber hidden units\n",
    "    network.add(Dense(units=3, activation='softmax')) #3 classes\n",
    "    init_weight = network.get_weights() # store init weights\n",
    "    network.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    acc=0\n",
    "    for lp in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_X, Y_3, test_size=0.3,stratify=df_y)\n",
    "        network.fit(X_train, y_train, epochs=200, batch_size=32,verbose=0)\n",
    "        test_loss, test_accuracy = network.evaluate(X_test, y_test)\n",
    "        network.set_weights(init_weight) # restore init weights\n",
    "        acc+=test_accuracy\n",
    "        print(\"test_loss:\", test_loss, \"  avg  test_accuracy:\", test_accuracy)\n",
    "\n",
    "    if maxtag<(acc/10):\n",
    "        maxtag= acc/10\n",
    "    print(\" avg acc:\", acc/10)\n",
    "\n",
    "print(\"max avg acc=>\",maxtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
